{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVDYF5oWKW8P"
      },
      "source": [
        "### **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yKXY_334JRr7"
      },
      "outputs": [],
      "source": [
        "# Install the HuggingFace Datasets and Evaluate libraries\n",
        "\n",
        "! pip install --quiet datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETpbkJVSKtn9",
        "outputId": "2a591cf5-24f3-4f42-cbd0-70b1ecb4bcce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Generating train split: 100%|██████████| 49971/49971 [00:00<00:00, 170335.49 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label'],\n",
              "        num_rows: 49971\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the Amharic news text classification dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "news_dataset = load_dataset(\"rasyosef/amharic-news-category-classification\")\n",
        "news_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ErdL0Q46kt",
        "outputId": "01c5e88e-fab6-46d7-e2ca-68094e96770f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label'],\n",
            "        num_rows: 39976\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label'],\n",
            "        num_rows: 9995\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "raw_datasets = news_dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
        "\n",
        "print(raw_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZVG8jAaLPZJ",
        "outputId": "6a4a4054-e4ed-4ca9-b1e4-6153ee770baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'headline': 'ዘላቂ  ልማትን ለማረጋገጥ  ያለመው  የአዲስ  አበባ የልማት አጀንዳ  ተቀባይነት አገኘ', 'category': 'ፖለቲካ', 'date': 'July 17, 2015', 'views': 'Unknown', 'article': 'በዛሬው ዕለት 3ኛው የፋይናንስ ጉባኤ ለልማት ጉባኤ ማጠቃለያ ላይ የኤፌዴሪ ጠቅላይ ሚኒስትርና የጉባኤው ፕሬዚዳንት ኃይለማሪያም ደሳለኝ እንደገለጹት ዘላቂ ልማት ለማረጋገጥ የሚያስችለውን የአዲስ አበባ የልማት አጀንዳ መሪ ዕቅድ ተግባራዊ ከአራት ቀን ጉባኤ በኋላ ስምምነትን አግኝቷል ።እንደ ጠቅላይ ሚኒስትር ኃይለማሪያም ገለጻ የፋይናንስ ለልማተ ጉባኤ የተካሄደበት \\xa0ሳምንት በዓለም ልማት ታሪክ ላይ ጉልህ ሥፍራ እንዳለው በመጠቆም \\xa0በንም \\xa0በልማት ወደ ኋላ አይቀርም የሚለውን መርህ \\xa0በታላቅ ጉጉት እየጠበቀው ይገኛል ብለዋል ።በጉባኤ \\xa0ያደጉ አገራት አብዛኛውን የልማት ድጋፍ ገና በማደግ ላይ ላሉ አገራት ለመመደብ \\xa0መስማማታቸው \\xa0የጉባኤ ትልቅ ውጤት ነው ያሉት ጠቅላይ ሚኒስትሩ \\xa0ያደጉ አገራት ከአጠቃላይ አገራዊ ገቢያቸው \\xa0ከዜሮነጥብ7 የሚሆነውን \\xa0ለልማት ድጋፍ እንዲያውሉና ከዚህም ውስጥ \\xa0ከ ዜሮ ነጥብ 15 እስከ ዜሮ ነጥብ ሃያ ድረስ \\xa0በድህነት ጫፍ ላይ ለሚገኙ አገራት እንደሚመደብ አስረድተዋል ።ጉባኤው \\xa0የግሉ ዘርፍ \\xa0ለልማት ያለውን አስተዋጽኦ አጉልቶ ማውጣቱን የጠቆሙት ጠቅላይ ሚኒስትሩ \\xa0 የመንግሥትና የግል ዘርፉ የኢንቨስትመንት መዋለ ንዋይ ትክክለኛ የኢኮኖሚ ዕድገትን እንደሚያመጣ \\xa0አብራርተዋል ።ኢትዮጵያ \\xa0እኤአ በ2025 \\xa0መካከለኛ \\xa0ገቢ ካላቸው አገራት ለማሰለፍ ከወዲሁ ውጥን ተይዞ እየተሠራ መሆኑንየጠቀሱት ጠቅላይ ሚኒሰትሩ የውጭ ቀጥታ ኢንቨስትመንትን በማጠናከርና ዕድገትን ይበልጥ በማፋጠን የተቀመጠው ግብ እንደሚሳካ ተናግረዋል ።3ኛው ዓለም አቀፍ \\xa0የፋይናንስ ለልማት ጉባኤ \\xa0ከ200 \\xa0በላይ በሚበልጡ የጉንዮሽ ጉባኤዎች ጭምር \\xa0ከፍተኛውየሆና የተሳትፎ \\xa0ግብረ መልሰ የተገኘበት መሆኑን የገለጹት ጠቅላይ ሚኒስትሩ \\xa0እንዚህምርጥ ተሞክሮዎችናግኝቶች \\xa0ለወደፊቱ \\xa0ለዓለም ትቅል ለውጥ ያመጣሉ ብለዋል ።የጂ 77ና ቻይናን \\xa0በመወከል ንግግር ያደረጉት የደቡብ አፍሪካ ተወካይ \\xa0እንዳብራሩት ለብዙ ወራት ቡድኑ \\xa0ድህነትን ጠራርጉ ለማጥፋት እንቅፋት የሆኑት ጉዳዮች ላይ ተጠምዶ ሲሰራ እንደቆየ በመግለጽ \\xa0መፍትሄው \\xa0የአቅመ ግንባታና የቴክኖሎጂ ሽግግር ለታጋዲ አገሮች ዘላቂ ልማተ መረጋጋጥ \\xa0ቁልፈ ሚና እንዳላቸው ገልጸዋል ።የደቡብ አፍሪካ ተወካዩ \\xa0የታጋዲ አገራት ህዝቦችን ኑሮ በሚለውጡ \\xa0ጉዳዮችብ \\xa0በተመለከተ \\xa0በጉባኤው \\xa0ውይይት ሲደረግባቸው እንደነበር በመጥቀስ \\xa0ዓለም አንደ አንድ ሆኖ ከተንቀሳቀሰ \\xa0 የተሻለች ዓለምን \\xa0መፍጠር ይቻላል ብለዋል ።የዓለም ባንክ ፤አይኤም ኤፍባሌሎች የዓለም ልማት \\xa0ባንኮች \\xa0ከ400 ቢሊዮን የአሜሪካ ዶላር \\xa0ለዘላዊ ልማት ግቦችን \\xa0ለማሳካት እንደሚያውሉ አስታውቀዋል ።', 'link': 'https://waltainfo.com/am/25478/', 'word_len': 270, 'label': 5}\n",
            "{'headline': 'ታሪክ ተሰራ !\\xa0', 'category': 'ስፖርት', 'date': 'March 19, 2017', 'views': 'Unknown', 'article': 'በቶታል ካፍ ቻምፒየንስ ሊግ የመጀመሪያ ዙር ማጣሪያ የመልስ ጨዋታ ወደ ዶሊሴ አቅንቶ ምንተስኖት አዳነ ብቸኛ ግብ 1-0 አሸንፎ የተመለሰው ቅዱስ ጊዮርጊስ በዛሬው የመልስ ጨዋታ በሰልሀዲን ሰኢድ ሁለት ግቦች ኤሲ ሊዮፓርድስን በድምር ውጤት 3-0 በማሸነፍ በኢትዮጵያ ክለቦች ታሪክ ለመጀመሪያ በአፍሪካ ቻምፒየንስ ሊግ ወደ ምድብ ድልድል መግባት የቻለ ቡድን በመሆን አይረሴ ታሪክን ማስቀመጥ ችሏል፡፡ፈረሰኞቹ ባሳለፍነው እሁድ ግቧን ያስቆጠረውና ከሜዳ በቀይ ካርድ የተሰናበተውን ምንተስኖት አዳነን በአዳነ ግርማ ከተኩት ውጪ ባሳለፍነው እሁድ የተጠቀሙበትን ተመሳሳይ የመጀመርያ 11 ተጫዋቾች ይዘው ነበር ጨዋታውን የጀመሩት፡፡በጨዋታው የመጀመሪያ 15 ደቂቃዎች ሁለቱም ቡድኖች ከተከላካይ በቀጥታ ወደፊት በሚጣሉ ረጃጅም ኳሶች በቶሎ ወደፊት ለመድረስ ጥረት ለማድረግ ሲሞክሩ ተስተውሏል፡፡ በመጀመሪያዎቹ ደቂቃዎች የቅዱስ ጊዮርጊስ ተከላካዮች በተለይም የመሀል ተከላካዮ ሰልሀዲን በርጌቾ በተደጋጋሚ ከትኩረት ማነስ በመነጨ ስህተቶች ቢሰራም የቡድኑ አጋሮቹ ስህተቶቹ አደጋ እንዳይፈጥሩ አድርገዋቸዋል፡፡ በአንጻሩ ኤሲ ሊዮፓርድሶች የምእራብ አፍሪካ ቡድኖች በሚታወቁበት የመስመር አጨዋወት ወደ ግራ መስመር ባደላ መልኩ በግራ መስመር ተከላካያቸው በኩል በተደጋጋሚ ጫና ለመፍጠር ሞክረዋል፡፡በ15ኛው ደቂቃ ላይ የኤሲ ሊዮፓርድሱ ግብጠባቂ ሉቱኑ በረጅሙ ሊለጋ የነበረውን ኳስ ሰልሀዲን ሰኢድ ተደርቦ በማስቆጠር የፈረሰኞቹን እድል ያሰፋችውን የመጀመሪያ ግብ ማስቆጠር ችሏል፡፡ከግቧ መቆጠር በኃላ በተደጋጋሚ ሊዮፓርድሶች በጨዋታው ጠንካራ የማጥቃት መሰንዘሪያ በነበረው የግራ መስመራቸው በኩል የቅዱስ ጊዮርጊሱን የቀኝ መስመር ተከላካይ የሆነውን ፍሬዘር ካሳ በተደጋጋሚ ቡድኑ ኳስ በሚያጣበት ጊዜ በሚኖረው የ4-5-1 ቅርፅ መሠረት ከሱ ፊት ከሚገኘው በሀይሉ አሰፋ በቂ የሆነ እገዛ ባለማግኘቱ በተደጋጋሚ 1ለ1 ከተቃራኒ ቡድን የመስመር ተጫዋቾች ጋር እየተገናኘ በቀላሉ ኳሶች ወደ መሀል ማሻማት ችለው ነበር፡፡ ነገርግን ኳሶቹ እምብዛም አደጋ መፍጠር አልቻሉም፡፡\\xa0በተቃራኒው ሊዮፓርድሶች ከማጥቃት ወደ መከላከል የሚያደርጉት ሽግግር እጅግ የዘገመ በመሆኑ መነሻነት ቅዱስ ጊዮርጊሶች በመልሶ ማጥቃት እንቅስቃሴ እጅግ በርካታ እድሎችን ቢያገኙም መጠቀም አልቻሉም፡፡ ከነዚህም መካከል በ19ኛው ደቂቃ ላይ ሰልሀዲን ሰኢድ ከቀኝ መስመር አብዱልከሪም ኒኪማ ያሻማለትን ኳስ በግንባሩ ገጭቶ የግቡ ቋሚ የመለሰበት እንዲሁም በ45ኛው ደቂቃ ሰልሀዲን ሰኢድ ከአቡዱልከሪም ኒኪማ የተቀበለውን ኳስ እራሱ ማስቆጠር ሲችል ለበሀይሉ አሰፋ አቀብሎት ያመከኗት ኳስ ተጠቃሽ ነበሩ፡፡ ከነዚህም በተጨማሪ ጊዮርጊሶች በመጀመሪያው አጋማሽ ከተጋጣሚያቸው ተሽለው ቢገኙም ያገኟቸውን በርካታ የግብ እድሎችን ግን መጠቀም ሳይችሉ ቀርተዋል፡፡በሁለተኛው አጋማሽ ሜዳ ላይ ከነበረው የጨዋታ እንቅስቃሴ ይልቅ ከሜዳ ውጪ የነበረው የፈረሰኞቹ ደጋፊዎች ድባብ እጅግ የሚያስደምም ነበር፡፡በዚህ አጋማሽ አበባው ቡጣቆ ከግራ መስመር አቅጣጫ ያሻማውን ኳስ አዳነ ግርማ በግንባሩ ገጭቶ ወደ ውጪ ከወጣበት ኳስ ውጪ ቅዱስ ጊዮርጊሶች ይህ ነው የሚባል የግብ እድል መፍጠር አልቻሉም፡፡ በአመዛኙም ውጤቱን ለማስጠበቅ በሚመስል በብዙ አጋጣሚዎች ወደ ኃላ አፈገግፍገው ሲጫወቱ ተስተውሏል፡፡ በአንጻሩ ለማለፍ ከሁለት በላይ ግቦች ያስፈልጋቸው የነበሩት ኤሲ ሊዮፓርዶች ከመጀመሪያው በተሻለ ቶሎ ቶሎ ወደ ግብ መድረስ ቢችሉም ግቦችን ለማስቆጠር ያደረጉት ጥረት ሳይሳካ ቀርቷል፡፡ጨዋታው ሊገባደድ ሲል በጭማሪ ሰአት የማእዘን ምት ለመሻማት የኤሲ ሊዮፓርድስ ተጫዋቾች ሙሉ በሙሉ ግብ ጠባቂውን ጨምሮ ወደ ቅዱስ ጊዮርጊስ የግብ ክልል መሄዳቸውን ተከትሎ በቀላሉ ተገጭቶ የተመለሰውን የማእዘን ምት ኳስ ሰልሀዲን ሰኢድ ከራሱ የግብ ክልል አንስቶ እየገፋ በመሄድ የፈሰኞቹን ድል ያረጋጠችውን ጎል አስቆጥሮ የቡድኑን ደጋፊዎች ወደ ወሰን የሌለው የደስታ ስሜት ውስጥ መክተት ችሏል፡፡የጨዋታውን መጠናቀቅ ያበሰረችውን ፌሽካ በእለቱ ጨዋታውን የመሩት ሱማሊያዊው አልቢትር ካሰሙ በኃላ በስታዲየሙ የነበረው የደስታን ስሜት ቃላቶች ከሚገልፁት በላይ ልዩ የነበረ ሲሆን የክለቡ የበላይ ጠባቂ የሆኑት አቶ አብነት ገብረመስቀልን ጨምሮ የቡድኑ አመራሮች እና ተጫዋቾች በከፍተኛ ሆኔታ ከደጋፊዎቻቸው ጋር ደስታቸውን ሲገልፁ ተስተውሏል፡፡ በዚህ ውጤት መሠረትም ቅዱስ ጊዮርጊስ ለመጀመሪያ ጊዜ በአፍሪካ ክለቦች ቻምፒየንስ ሊግ ውድድር ላይ የምድብ ድልድል ውስጥ የገባ የመጀመርያው ኢትዮጵያዊ ክለብ በመሆን ታሪክ መስራት ችሏል፡፡', 'link': 'https://soccerethiopia.net/football/26554', 'word_len': 484, 'label': 2}\n",
            "{'headline': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None), 'date': Value(dtype='string', id=None), 'views': Value(dtype='string', id=None), 'article': Value(dtype='string', id=None), 'link': Value(dtype='string', id=None), 'word_len': Value(dtype='int64', id=None), 'label': ClassLabel(names=['ሀገር አቀፍ ዜና', 'መዝናኛ', 'ስፖርት', 'ቢዝነስ', 'ዓለም አቀፍ ዜና', 'ፖለቲካ'], id=None)}\n"
          ]
        }
      ],
      "source": [
        "print(raw_datasets['train'][0])\n",
        "print(raw_datasets['test'][0])\n",
        "print(raw_datasets['train'].features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ipgOz-R2l7",
        "outputId": "e5ba07c7-4e6c-48e4-c617-88fedc4431a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|██████████| 39976/39976 [00:00<00:00, 42254.81 examples/s]\n",
            "Filter: 100%|██████████| 9995/9995 [00:00<00:00, 41298.42 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label'],\n",
              "        num_rows: 38966\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label'],\n",
              "        num_rows: 9735\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove articles that are too short\n",
        "\n",
        "raw_datasets = raw_datasets.filter(lambda x: x['word_len'] >= 32)\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2wa3NvEUDEs",
        "outputId": "091a4558-c77c-4c00-ca30-d9aec26f12b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ሀገር አቀፍ ዜና', 'መዝናኛ', 'ስፖርት', 'ቢዝነስ', 'ዓለም አቀፍ ዜና', 'ፖለቲካ']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = raw_datasets['train'].features['label'].names\n",
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9k_70_vhcgz",
        "outputId": "0507f67b-fadf-4a9b-f181-c10e243207e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 38966/38966 [00:07<00:00, 4933.43 examples/s]\n",
            "Map: 100%|██████████| 9735/9735 [00:01<00:00, 5443.07 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label', 'full_article'],\n",
              "        num_rows: 38966\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label', 'full_article'],\n",
              "        num_rows: 9735\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate the title and article\n",
        "raw_datasets = raw_datasets.map(lambda x: {\"full_article\" : x[\"headline\"] + \"\\n\" + x[\"article\"]})\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFWnv71FMvse"
      },
      "source": [
        "### **Preprocessing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "50f076191b84452ab54fb130e10de54b",
            "d8ae0e9d04104b94ac2d1e4827840229",
            "67d83e8965634f63b77cb43e80a16e53",
            "d97717778f6c47e2871f2f8dc8e6cd80",
            "7351753d9aca456d8bbb1888f4deab21",
            "00ac74e6fd1b4b5ea94b25d0cd2fcd31",
            "2057b2dbeced422ab46f6cda5d6f257d",
            "2d2e55ddcf334f8897ef1e3e4875cf26",
            "195bfface3644c1780478ad8f21f4b84",
            "35cfa8c57d9c40d88d4bd23b4c41807e",
            "b5a85ee2b1834a16a7485a7a92f84266"
          ]
        },
        "id": "0ci2nufOMFwm",
        "outputId": "6834260f-f202-4430-d1a4-724712574325"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 38966/38966 [00:25<00:00, 1516.10 examples/s]\n",
            "Map: 100%|██████████| 9735/9735 [00:10<00:00, 933.78 examples/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label', 'full_article', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 38966\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['headline', 'category', 'date', 'views', 'article', 'link', 'word_len', 'label', 'full_article', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 9735\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "checkpoint = \"FacebookAI/xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Tokenize the dataset\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(example['full_article'], truncation=True, max_length=512)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets\n",
        "\n",
        "# Use a data collator to apply dynamic padding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='pt')\n",
        "\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxhrXKJAWp_Z"
      },
      "source": [
        "### **Finetuning the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsaWJBAtzbE0",
        "outputId": "9b23469a-5aed-468f-b807-4183e98a630f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# roberta-base\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(categories),\n",
        "    id2label = {i: lbl for i, lbl in enumerate(categories)},\n",
        "    label2id = {lbl: i for i, lbl in enumerate(categories)},\n",
        "    device_map=\"cuda\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rnoH2Wk-mMhZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 16\n",
        "gradient_accumulation_steps = 4\n",
        "epochs = 5\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=checkpoint+\"-finetuned\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    fp16=True,\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-hZQNWwo5kk",
        "outputId": "d1ec2e7b-8ce7-41bb-d381-245837eba1a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 4.26MB/s]\n",
            "Downloading builder script: 100%|██████████| 7.56k/7.56k [00:00<?, ?B/s]\n",
            "Downloading builder script: 100%|██████████| 7.38k/7.38k [00:00<?, ?B/s]\n",
            "Downloading builder script: 100%|██████████| 6.79k/6.79k [00:00<?, ?B/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  metric1 = evaluate.load(\"accuracy\")\n",
        "  metric2 = evaluate.load(\"precision\")\n",
        "  metric3 = evaluate.load(\"recall\")\n",
        "  metric4 = evaluate.load(\"f1\")\n",
        "\n",
        "  logits, labels = eval_preds\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "  precision = metric2.compute(predictions=predictions, references=labels, average='macro')[\"precision\"]\n",
        "  recall = metric3.compute(predictions=predictions, references=labels, average='macro')[\"recall\"]\n",
        "  f1 = metric4.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
        "\n",
        "  return {\n",
        "      \"accuracy\": accuracy,\n",
        "      \"precision\": precision,\n",
        "      \"recall\": recall,\n",
        "      \"f1\": f1\n",
        "  }\n",
        "\n",
        "compute_metrics(([[1,0], [0,1]], [0,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "M3nt3pm7n8st",
        "outputId": "06b878cd-56ea-4525-b707-08683a61bb07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fikre\\AppData\\Local\\Temp\\ipykernel_27576\\4290875398.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            " 19%|█▊        | 567/3045 [20:50<1:37:24,  2.36s/it]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      5\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3612\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3613\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:2244\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2244\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fikre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ") \n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxcSxsJYgTrs"
      },
      "source": [
        "### **Model Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i6lbff_eZPh",
        "outputId": "b6c4c773-1d33-466e-892f-15eb53b3ba84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['labels', 'input_ids', 'attention_mask']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'f1': 0.8756344650022968}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load metrics and evaluate the model\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "eval_dataset = tokenized_datasets[\"test\"].remove_columns([\n",
        "    'headline', 'category', 'date', 'views',\n",
        "    'article', 'link', 'word_len', 'full_article'\n",
        "    ]).rename_column(\"label\", \"labels\").with_format(\"torch\")\n",
        "\n",
        "print(eval_dataset.column_names)\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=64,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "import evaluate\n",
        "import torch\n",
        "\n",
        "y_pred, y_test = [], []\n",
        "\n",
        "metric = evaluate.load(\"f1\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "  batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**batch)\n",
        "\n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=-1)\n",
        "  metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "  y_pred.extend(predictions.cpu().numpy())\n",
        "  y_test.extend(batch[\"labels\"].cpu().numpy())\n",
        "metric.compute(average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JPNAvx6gcxc"
      },
      "outputs": [],
      "source": [
        "len(y_pred), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlNRZwFRN4HB",
        "outputId": "4218c8a8-e73d-4b6b-da8d-06d9b18b1cec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'f1': 0.8986341914792896}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=y_pred, references=y_test, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peVet6RYC7NZ",
        "outputId": "5238c275-f7c9-43d8-b9a6-42022047cbe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3516,    6,   12,  135,   80,  209],\n",
              "       [  15,   90,    1,    0,    2,    1],\n",
              "       [   3,    0, 1946,    0,    1,    2],\n",
              "       [ 121,    1,    0,  584,    0,   72],\n",
              "       [  67,    1,    1,    2, 1024,   12],\n",
              "       [ 150,    6,    3,   80,    6, 1586]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3pysPvEvLVv",
        "outputId": "d9a601d1-f0bc-4242-ae18-f00b8778925c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      3958\n",
            "           1       0.87      0.83      0.85       109\n",
            "           2       0.99      1.00      0.99      1952\n",
            "           3       0.73      0.75      0.74       778\n",
            "           4       0.92      0.93      0.92      1107\n",
            "           5       0.84      0.87      0.85      1831\n",
            "\n",
            "    accuracy                           0.90      9735\n",
            "   macro avg       0.88      0.88      0.88      9735\n",
            "weighted avg       0.90      0.90      0.90      9735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VAxB9YqxqFCG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ac74e6fd1b4b5ea94b25d0cd2fcd31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "195bfface3644c1780478ad8f21f4b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2057b2dbeced422ab46f6cda5d6f257d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2e55ddcf334f8897ef1e3e4875cf26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35cfa8c57d9c40d88d4bd23b4c41807e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f076191b84452ab54fb130e10de54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8ae0e9d04104b94ac2d1e4827840229",
              "IPY_MODEL_67d83e8965634f63b77cb43e80a16e53",
              "IPY_MODEL_d97717778f6c47e2871f2f8dc8e6cd80"
            ],
            "layout": "IPY_MODEL_7351753d9aca456d8bbb1888f4deab21"
          }
        },
        "67d83e8965634f63b77cb43e80a16e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2e55ddcf334f8897ef1e3e4875cf26",
            "max": 9735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_195bfface3644c1780478ad8f21f4b84",
            "value": 9735
          }
        },
        "7351753d9aca456d8bbb1888f4deab21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a85ee2b1834a16a7485a7a92f84266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ae0e9d04104b94ac2d1e4827840229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ac74e6fd1b4b5ea94b25d0cd2fcd31",
            "placeholder": "​",
            "style": "IPY_MODEL_2057b2dbeced422ab46f6cda5d6f257d",
            "value": "Map: 100%"
          }
        },
        "d97717778f6c47e2871f2f8dc8e6cd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35cfa8c57d9c40d88d4bd23b4c41807e",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a85ee2b1834a16a7485a7a92f84266",
            "value": " 9735/9735 [00:33&lt;00:00, 266.96 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
